accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
confusion_matrix = table(predictions, iris$Species)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
install.packages("gbm")
library(gbm)
data(iris)
iris$Species<-as.numeric(factor(iris$Species))
set.seed(123)
boosted_model<-gbm(Species~., data=iris, distribution = "multinomial", n.trees=100, interaction.depth=3, shrinkage=0.1)
predictions<-predict(boosted_model, newdata=iris, n.trees=100, type="response")
predicted_labels<-apply(predictions,1,which.max)
table(predicted_labels,iris$Species)
install.packages("gbm")
library(gbm)
data(iris)
iris$Species<-as.numeric(factor(iris$Species))
set.seed(123)
boosted_model<-gbm(Species~., data=iris, distribution = "multinomial", n.trees=100, interaction.depth=3, shrinkage=0.1)
predictions<-predict(boosted_model, newdata=iris, n.trees=100, type="response")
predicted_labels<-apply(predictions,1,which.max)
table(predicted_labels,iris$Species)
install.packages("gbm")
library(gbm)
data(iris)
iris$Species<-as.numeric(factor(iris$Species))
set.seed(123)
boosted_model<-gbm(Species~., data=iris, distribution = "multinomial", n.trees=100, interaction.depth=3, shrinkage=0.1)
predictions<-predict(boosted_model, newdata=iris, n.trees=100, type="response")
predicted_labels<-apply(predictions,1,which.max)
table(predicted_labels,iris$Species)
install.packages("gbm")
library(gbm)
#install.packages("gbm")
library(gbm)
data(iris)
iris$Species<-as.numeric(factor(iris$Species))
set.seed(123)
boosted_model<-gbm(Species~., data=iris, distribution = "multinomial", n.trees=100, interaction.depth=3, shrinkage=0.1)
predictions<-predict(boosted_model, newdata=iris, n.trees=100, type="response")
predicted_labels<-apply(predictions,1,which.max)
table(predicted_labels,iris$Species)
confusion_matrix = table(predicted_labels, iris$Species)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
install.packages("gbm")
install.packages("gbm")
#install.packages("gbm")
library(gbm)
data(iris)
set.seed(123)
iris$Species <- as.numeric(factor(iris$Species))  # Convert species to numeric factor levels
boosted_model <- gbm(Species ~ ., data = iris, distribution = "multinomial",
n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
predictions <- predict(boosted_model, newdata = iris, n.trees = 100, type = "response")
predicted_labels <- apply(predictions, 1, which.max)
confusion_matrix <- table(predicted_labels, iris$Species)
confusion_matrix
confusion_matrix = table(predicted_labels, iris$Species)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
#install.packages("gbm")
library(gbm)
data(iris)
set.seed(123)
boosted_model <- gbm(Species ~ ., data = iris, distribution = "multinomial",
n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
predictions <- predict(boosted_model, newdata = iris, n.trees = 100, type = "response")
predicted_labels <- apply(predictions, 1, which.max)
confusion_matrix <- table(predicted_labels, iris$Species)
confusion_matrix
predicted_labels <- apply(predictions, 1)
confusion_matrix <- table(predicted_labels, iris$Species)
confusion_matrix
predictions <- predict(boosted_model, newdata = iris, n.trees = 100, type = "response")
predicted_labels <- apply(predictions, 1, which.max)
confusion_matrix <- table(predicted_labels, iris$Species)
confusion_matrix
confusion_matrix = table(predicted_labels, iris$Species)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
predictions
predicted_labels
confusionMatrix(predicted_labels, iris$Specie)
caret
library(caret)
data(iris)
set.seed(123)
boosted_model <- gbm(Species ~ ., data = iris, distribution = "multinomial",
n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
predictions <- predict(boosted_model, newdata = iris, n.trees = 100, type = "response")
predicted_labels <- apply(predictions, 1, which.max)
confusionMatrix(predicted_labels, iris$Specie)
confusion_matrix <- table(predicted_labels, iris$Species)
confusion_matrix
accuracy <- sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
confusionMatrix(predicted_labels, iris$Species)
library(ggplot2)
ggplot(iris, aes(x=Petal.Length,  y=Petal.Width))+
geom_point(aes(shape=factor(Species)))+
geom_point(aes(color=factor(Species)))+
geom_smooth(method="rm")
ggplot(iris, aes(x=Petal.Length,  y=Petal.Width))+
geom_point(aes(shape=factor(Species)))+
geom_point(aes(color=factor(Species)))+
geom_smooth(method="lm")
library(ggplot2)
ggplot(iris, aes(x=Petal.Length))+
geom_histogram(color="black", fill="yellow", bin=20)
ggplot(iris, aes(x = Sepal.Length)) +
geom_histogram(color="black", fill="yellow", bins=20,)
ggplot(iris, aes(x = Sepal.Length)) +
geom_histogram(color="black", fill="yellow", bins=20,)
library(ggplot2)
ggplot(iris, aes(x=Petal.Length))+
geom_histogram(color="black", fill="yellow", bin=20)
ggplot(iris, aes(x=Petal.Length))+
geom_histogram(color="black", fill="yellow", bina=20)
ggplot(iris, aes(x=Petal.Length))+
geom_histogram(color="black", fill="yellow", bin=20)
ggplot(iris, aes(x=Petal.Length))+
geom_histogram(color="black", fill="yellow", bins=20)
library(ggplot2)
ggplot(iris, aes(x=Petal.Length))+
geom_histogram(color="black", fill="yellow", bins=20)
ggplot(iris, aes(x=Sepal.Length))+
geom_histogram(color="black", fill="yellow", bins=20, )
library(carel)
library(caret)
library(caret)
library(e1071)
dataset = read.csv("Soybean.csv")
sum(is.na(dataset))
sum(is.na(dataset))
soybean = no.omit(dataset)
sum(is.na(soybean))
sum(is.na(dataset))
soybean = na.omit(dataset)
dataset = read.csv("Soybean.csv")
sum(is.na(dataset))
soybeann = na.omit(dataset)
sum(is.na(soybeann))
preproc = preProcess(soybean[, -1], method = c("center, scale"))
preproc = preProcess(soybean$Class, soybean[, -1], method = c("center, scale"))
sum(is.na(soybean))
preproc = preProcess(soybean[, -1], method = c("center, scale"))
preproc = preProcess(soybean[, -1], method = c("centre, scale"))
preproc = preProcess(soybean[, -1], method = c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_label = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_label = soybean$Class[-splitIndex]
nb_model = naiveBayes(Class~., train_data)
nb_predictor = predict(nb_model, test_data)
gc()
confusionMatrix(soybean$Class, nb_predictor)
nb_predictor = predict(nb_model, test_data)
confusionMatrix(nb_predictor, test_label)
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_label = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_label = soybean$Class[-splitIndex]
nb_model = naiveBayes(Class~., train_data)
nb_predictor = predict(nb_model, test_data)
confusionMatrix(nb_predictor, test_label)
confusionMatrix(test_label, nb_predictor)
soybean$Class = factor(soybean$Class)
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_label = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_label = soybean$Class[-splitIndex]
nb_model = naiveBayes(Class~., train_data)
nb_predictor = predict(nb_model, test_data)
confusionMatrix(test_label, nb_predictor)
source("C:/Users/noelm/Documents/PROJECTS/College-Lab-Works/S5 ML (Machine Learning)/Internals Practice(Learn from this)/naiveBayes_ip.R")
library(e1071)
library(caret)
dataset = read.csv("Soybean.csv")
sum(is.na(dataset))
soybean=na.omit(dataset)
preproc = preProcess(soybean[, -1], method = c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
set.seed(123)
soybean$Class = factor(soybean$Class)
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_labels = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_labels = soybean$Class[-splitIndex]
naiveBayes_model = naiveBayes(Class~., train_data)
naiveBayes_predictions = predict(naiveBayes_model, test_data)
confusionMatrix(test_labels, naiveBayes_predictions)
dataset = read.csv("Soybean.csv")
sum(is.na(dataset))
soybean = na.omit(dataset)
sum(is.na(soybean))
preproc = preProcess(soybean[, -1], method = c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
soybean$Class = factor(soybean$Class)
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_label = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_label = soybean$Class[-splitIndex]
nb_model = naiveBayes(Class~., train_data)
nb_predictor = predict(nb_model, test_data)
confusionMatrix(test_label, nb_predictor)
library(rpart)
library(rpart.plot)
titanic = read.csv("titanic.csv")
View(titanic)
titanic = read.csv("titanic.csv")
titanic = titanic[, c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Survived")]
View(titanic)
View(titanic)
titanic$Sex = as.factor(titanic$Sex)
dt_model = rpart(Survived~., titanic, method="class")
dt_model
prp(dt_model)
dt_predictor = predict(dt_model, titanic, type="class")
confusion_matrix = table(titanic$Survived, dt_predictor)
confusion_matrix
accuracy
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
library(rpart)
library(rpart.plot)
titanic = read.csv("titanic.csv")
titanic = titanic[, c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Survived")]
titanic$Sex = as.factor(titanic$Sex)
dt_model = rpart(Survived~., titanic, method="class")
dt_model
prp(dt_model)
dt_predictor = predict(dt_model, titanic, type="class")
confusion_matrix = table(titanic$Survived, dt_predictor)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
library(rpart)
library(rpart.plot)
titanic = read.csv('titanic.csv')
titanic = titanic[, c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Survived")]
sum(is.na(titanic))
titanic = na.omit(titanic)
titanic$Sex = as.factor(titanic$Sex)
decisionTree_model = rpart(Survived~., titanic, method = "class")
print(decisionTree_model)
prp(decisionTree_model)
decisionTree_predictor = predict(decisionTree_model, titanic, type="class")
confusion_matrix = table(titanic$Survived, decisionTree_predictor)
confusion_matrix
accuracy = sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
sum(is.na(titanic))
titanic = na.omit(titanic)
titanic$Sex = as.factor(titanic$Sex)
dt_model = rpart(Survived~., titanic, method="class")
dt_model
prp(dt_model)
dt_predictor = predict(dt_model, titanic, type="class")
confusion_matrix = table(titanic$Survived, dt_predictor)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
library(rpart)
library(rpart.plot)
titanic = read.csv("titanic.csv")
titanic = titanic[, c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Survived")]
sum(is.na(titanic))
titanic = na.omit(titanic)
titanic$Sex = as.factor(titanic$Sex)
dt_model = rpart(Survived~., titanic, method="class")
dt_model
prp(dt_model)
dt_predictor = predict(dt_model, titanic, type="class")
confusion_matrix = table(titanic$Survived, dt_predictor)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
library(rpart)
library(rpart.plot)
titanic = read.csv('titanic.csv')
titanic = titanic[, c("Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Survived")]
sum(is.na(titanic))
titanic = na.omit(titanic)
titanic$Sex = as.factor(titanic$Sex)
decisionTree_model = rpart(Survived~., titanic, method = "class")
print(decisionTree_model)
prp(decisionTree_model)
decisionTree_predictor = predict(decisionTree_model, titanic, type="class")
confusion_matrix = table(titanic$Survived, decisionTree_predictor)
confusion_matrix
accuracy = sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
library(randomForest)
library(e1071)
library(caret)
dataset = read.csv("Soybean.csv")
sum(is.na(dataset))
soybean = na.omit(dataset)
preproc = preProcess(soyvean[, -1], method=c("center", "scale"))
preproc = preProcess(soybean[, -1], method=c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
preproc = preProcess(soybean[, -1], method=c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
soybean$Class = factor(soybean$Class)
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_label = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_label = soybean$Class[-splitIndex]
rf_model = train(Class~., test_data, metho="rf")
rf_predictor = predict(rf_model, train_label)
rf_model = train(Class~., train_data, metho="rf")
rf_predictor = predict(rf_model, test_data)
confusionMatrix(rf_predictor, test_label)
library(e1071)
library(caret)
library(randomForest)
dataset = read.csv("Soybean.csv")
sum(is.na(dataset))
soybean=na.omit(dataset)
preproc = preProcess(soybean[, -1], method = c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
set.seed(123)
soybean$Class = factor(soybean$Class)
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_labels = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_labels = soybean$Class[-splitIndex]
randomForest_model = train(Class~., train_data, method="rf")
set.seed(123)
soybean$Class = factor(soybean$Class)
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_labels = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_labels = soybean$Class[-splitIndex]
randomForest_model = train(Class~., train_data, method="rf")
randomForest_predictions = predict(randomForest_model, test_data)
confusionMatrix(test_labels, randomForest_predictions)
data("iris")
library(e1071)
library(caret)
data("iris")
set.seed(123)
View(iris)
confusion_matrix = table(knn_model,test_label)
train_label = iris$Species[splitIndex]
test_data = iris[-splitIndex, -5]
test_label = iris$Species[-splitIndex]
knn_model = knn(train_data, test_data, train_label, k=1)
confusion_matrix = table(knn_model,test_label)
train_data = iris[splitIndex, -5]
train_label = iris$Species[splitIndex]
test_data = iris[-splitIndex, -5]
test_label = iris$Species[-splitIndex]
knn_model = knn(train_data, test_data, train_label, k=1)
knn_model = knn(train_data, test_data, train_label, k=1)
library(e1071)
library(caret)
data("iris")
set.seed(123)
iris$Species = factor(iris$Species)
splitIndex = createDataPartition(iris$Species, p=0.8, list=FALSE)
train_data = iris[splitIndex, -5]
train_label = iris$Species[splitIndex]
test_data = iris[-splitIndex, -5]
test_label = iris$Species[-splitIndex]
knn_model = knn(train_data, test_data, train_label, k=1)
knn_model = knn3(train_data, test_data, train_label, k=1)
test_label = iris$Species[-splitIndex]
knn_model = knn(train_data, test_data, train_label, k=1)
splitIndex = createDataPartition(iris$Species, p=0.8, list=FALSE)
train_data = iris[splitIndex, -5]
train_label = iris$Species[splitIndex]
test_data = iris[-splitIndex, -5]
test_label = iris$Species[-splitIndex]
knn_model = knn(train_data, test_data, train_label, k=1)
library(caret)
data(iris)
set.seed(123)
splitIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
train_data <- iris[splitIndex, -5]
train_labels <- iris$Species[splitIndex]
test_data <- iris[-splitIndex, -5]
test_labels <- iris$Species[-splitIndex]
knn_model <- knn(train_data, test_data, train_labels, k = 1)
confusionMatrix(test_labels, knn_model)
library(caret)
data(iris)
set.seed(123)
splitIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
train_data <- iris[splitIndex, -5]
train_labels <- iris$Species[splitIndex]
test_data <- iris[-splitIndex, -5]
test_labels <- iris$Species[-splitIndex]
knn_model <- knn(train_data, test_data, train_labels, k = 1)
library(class)
data(iris)
set.seed(123)
splitIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
train_data <- iris[splitIndex, -5]
train_labels <- iris$Species[splitIndex]
test_data <- iris[-splitIndex, -5]
test_labels <- iris$Species[-splitIndex]
knn_model <- knn(train_data, test_data, train_labels, k = 1)
confusionMatrix(test_labels, knn_model)
library(class)
data("iris")
set.seed(123)
iris$Species = factor(iris$Species)
splitIndex = createDataPartition(iris$Species, p=0.8, list=FALSE)
train_data = iris[splitIndex, -5]
train_label = iris$Species[splitIndex]
test_data = iris[-splitIndex, -5]
test_label = iris$Species[-splitIndex]
knn_model = knn(train_data, test_data, train_label, k=1)
confusion_matrix = table(knn_model,test_label)
confusion_matrix
library(caret)
data(iris)
set.seed(123)
splitIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
train_data <- iris[splitIndex, -5]
train_labels <- iris$Species[splitIndex]
test_data <- iris[-splitIndex, -5]
test_labels <- iris$Species[-splitIndex]
test_labels <- iris$Species[-splitIndex]
svm_model = svm(train_data, train_label, kernel="radial", cost=1)
svm_predictor = predict(svm_model, test_data)
confusionMatrix(svm_predictor, test_label)
library(e1071)
library(caret)
data(iris)
set.seed(123)
splitIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
train_data <- iris[splitIndex, -5]
train_labels <- iris$Species[splitIndex]
test_data <- iris[-splitIndex, -5]
test_labels <- iris$Species[-splitIndex]
svm_model <- svm(train_data, train_labels, kernel = "radial", cost = 1)
svm_predictions <- predict(svm_model, test_data)
confusionMatrix(svm_predictions,test_labels)
seed.set(123)
set.seed(123)
data("iris")
library(ipred)
data("iris")
set.seed(123)
bag_model = baggin(Species~., iris, nbagg=50)
bag_model = bagging(Species~., iris, nbagg=50)
predictor = predict(bag_model, iris)
confusion_matrix(predictor, iris$Species)
library(ipred)
data("iris")
set.seed(123)
bag_model = bagging(Species~., iris, nbagg=50)
predictor = predict(bag_model, iris)
confusion_matrix(predictor, iris$Species)
confusion_matrix=table(predictor, iris$Species)
confusion_matrix
accuracy = sum(diag(confusion_matrix))/sum(confusion_matrix)
accuracy
library(gbm)
data(iris)
set.seed(123)
library(gbm)
data(iris)
set.seed(123)
bModel = gbm(Species~., iris, n.trees=100, distribution="multinomial", interaction.depth=3, shrinkage=0.1)
bPredictor = predict(bModel, iris, n.trees=100, type="response")
predictLabel = apply(bPredictor, 1, which.max)
confusion_matrix = table(iris$Species, predictLabel)
confusion_matrix
library(ggplot2)
data(Titanic)
data(Titanic)
df = as.data.frame(Titanic)
ggplot(df, aes(x=Freq))+
geom_histogram(color= "black", fill="blue", bins=30)
data("Titanic")
df = as.data.frame(Titanic)
Titanic
data(Titanic)
soybean$Class = as.numeric(factor(soybean$Class))
splitIndex = createDataPartition(soybean$Class, p=0.8, list=FALSE)
train_data = soybean[splitIndex, ]
train_labels = soybean$Class[splitIndex]
test_data = soybean[-splitIndex, ]
test_labels = soybean$Class[-splitIndex]
dataset = read.csv("Soybean.csv")
sum(is.na(dataset))
soybean=na.omit(dataset)
preproc = preProcess(soybean[, -1], method = c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
View(soybean)
preproc = preProcess(soybean[, -1], method = c("center", "scale"))
soybean[, -1] = predict(preproc, soybean[, -1])
set.seed(123)
soybean$Class = as.numeric(factor(soybean$Class))
soybean
View(soybean)
